# Llama-68M-Chat-v1-rasp
The following model was used for the application.

https://huggingface.co/Felladrin/Llama-68M-Chat-v1
# Execution result on raspberry pi
The measured execution time was roughly 30 seconds.

Ask the same question and you will get the same answer.
![Llama Chatbot_page-0001](https://github.com/user-attachments/assets/dd926e7a-130b-4536-b9da-dd1824383123)
I asked a few questions. the Llama model would sometimes answer the question correctly, but sometimes incorrectly. The same sentence was then generated many times for the question “What is a smart phone?”. In addition, the text ends in the middle of a sentence because it continues to generate up to the set number of characters (200).
![Llama Chatbot2_page-0001](https://github.com/user-attachments/assets/9c62b013-3b4c-4157-a7d0-5e50e493b48a)

# Directory structure
![image](https://github.com/user-attachments/assets/50b1a16a-d272-4725-8821-6ac2990c83e9)
